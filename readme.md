ğŸ§  Machine Downtime Prediction â€” End-to-End MLOps Pipeline
â”‚
â”œâ”€â”€ ğŸ“˜ Project Overview
â”‚   â”‚
â”‚   â”œâ”€â”€ This project demonstrates a complete MLOps workflow for predicting machine downtime
â”‚   â”‚   in an industrial environment.
â”‚   â”‚
â”‚   â”œâ”€â”€ The pipeline automates every step â€” data ingestion, preprocessing, model training,
â”‚   â”‚   evaluation, data drift detection, retraining, and deployment â€” using:
â”‚   â”‚       â”œâ”€â”€ DVC (Data Version Control) â€” reproducibility
â”‚   â”‚       â”œâ”€â”€ Evidently AI â€” continuous data drift monitoring
â”‚   â”‚       â”œâ”€â”€ Scikit-learn â€” machine learning models
â”‚   â”‚       â””â”€â”€ Streamlit / Flask â€” deployment
â”‚   â”‚
â”‚   â””â”€â”€ The goal is to build a self-learning predictive system that monitors its performance,
â”‚       detects when input data changes, and retrains automatically when required.
â”‚
â”œâ”€â”€ ğŸ“ Folder Structure
â”‚   â”‚
â”‚   â”œâ”€â”€ mlops/
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”‚   â”œâ”€â”€ raw/                  # Original dataset (Machine_downtime.csv)
â”‚   â”‚   â”‚   â”œâ”€â”€ processed/            # Cleaned dataset after preprocessing (train.csv)
â”‚   â”‚   â”‚   â””â”€â”€ live/                 # Live simulation data (current_low, current_mid, current_high)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ src/                      # Source scripts for each pipeline stage
â”‚   â”‚   â”‚   â”œâ”€â”€ preprocess.py
â”‚   â”‚   â”‚   â”œâ”€â”€ train.py
â”‚   â”‚   â”‚   â”œâ”€â”€ evaluate.py
â”‚   â”‚   â”‚   â””â”€â”€ detect_drift.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ models/                   # Trained model files (model.pkl)
â”‚   â”‚   â”œâ”€â”€ reports/                  # Drift and metric reports (HTML/JSON)
â”‚   â”‚   â”œâ”€â”€ app.py                    # Streamlit/Flask app for deployment
â”‚   â”‚   â”œâ”€â”€ dvc.yaml                  # DVC pipeline definition
â”‚   â”‚   â”œâ”€â”€ params.yaml               # Central configuration file
â”‚   â”‚   â”œâ”€â”€ requirements.txt          # Python dependencies
â”‚   â”‚   â””â”€â”€ drift_history.json        # Historical record of drift detections
â”‚
â”œâ”€â”€ âš™ï¸ Step-by-Step Pipeline Description
â”‚
â”‚   â”œâ”€â”€ 1ï¸âƒ£ Data Ingestion & Preprocessing
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ Raw dataset:
â”‚   â”‚   â”‚       data/raw/Machine_downtime.csv
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ Script used:
â”‚   â”‚   â”‚       src/preprocess.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ Description:
â”‚   â”‚   â”‚       â”œâ”€â”€ Handles missing values
â”‚   â”‚   â”‚       â”œâ”€â”€ Encodes categorical features
â”‚   â”‚   â”‚       â”œâ”€â”€ Removes irrelevant columns
â”‚   â”‚   â”‚       â””â”€â”€ Saves cleaned dataset as data/processed/train.csv
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ Configuration (params.yaml):
â”‚   â”‚           preprocess:
â”‚   â”‚             input_file: data/raw/Machine_downtime.csv
â”‚   â”‚             output_file: data/processed/train.csv
â”‚   â”‚
â”‚   â”œâ”€â”€ 2ï¸âƒ£ Model Training
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ Stage name: train
â”‚   â”‚   â”œâ”€â”€ Script: src/train.py
â”‚   â”‚   â”œâ”€â”€ Algorithm: RandomForestClassifier
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ Parameters (params.yaml):
â”‚   â”‚   â”‚       train:
â”‚   â”‚   â”‚         model_type: RandomForestClassifier
â”‚   â”‚   â”‚         test_size: 0.2
â”‚   â”‚   â”‚         random_state: 42
â”‚   â”‚   â”‚         smote: true
â”‚   â”‚   â”‚         n_estimators: 100
â”‚   â”‚   â”‚         max_depth: 10
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ Target variable:
â”‚   â”‚   â”‚       Downtime (1 = Failure, 0 = Non-Failure)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ Input features:
â”‚   â”‚   â”‚       â”œâ”€â”€ Hydraulic Pressure
â”‚   â”‚   â”‚       â”œâ”€â”€ Coolant Temperature
â”‚   â”‚   â”‚       â”œâ”€â”€ Tool Vibration
â”‚   â”‚   â”‚       â”œâ”€â”€ Torque
â”‚   â”‚   â”‚       â”œâ”€â”€ Spindle Speed
â”‚   â”‚   â”‚       â””â”€â”€ Voltage
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ Output model file:
â”‚   â”‚           models/model.pkl
â”‚   â”‚
â”‚   â”œâ”€â”€ 3ï¸âƒ£ Model Evaluation
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ Script used:
â”‚   â”‚   â”‚       src/evaluate.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ Process:
â”‚   â”‚   â”‚       â”œâ”€â”€ Load data and trained model
â”‚   â”‚   â”‚       â”œâ”€â”€ Split into 80/20 train-test
â”‚   â”‚   â”‚       â”œâ”€â”€ Compute metrics (Accuracy, F1-score, Precision, Recall)
â”‚   â”‚   â”‚       â””â”€â”€ Save results to reports/metrics.json
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ Example output:
â”‚   â”‚           accuracy: 0.83
â”‚   â”‚           f1_score: 0.81
â”‚   â”‚           precision: 0.82
â”‚   â”‚           recall: 0.79
â”‚   â”‚
â”‚   â”œâ”€â”€ 4ï¸âƒ£ Continuous Data Drift Detection
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ Script used:
â”‚   â”‚   â”‚       src/detect_drift.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ Tool: Evidently AI
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ Reference dataset:
â”‚   â”‚   â”‚       data/processed/train.csv
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ Live datasets:
â”‚   â”‚   â”‚       â”œâ”€â”€ data/live/current_low.csv
â”‚   â”‚   â”‚       â”œâ”€â”€ data/live/current_mid.csv
â”‚   â”‚   â”‚       â””â”€â”€ data/live/current_high.csv
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ Generated reports:
â”‚   â”‚   â”‚       â”œâ”€â”€ reports/drift_report_low.html
â”‚   â”‚   â”‚       â””â”€â”€ reports/drift_low.json
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ Drift detection process:
â”‚   â”‚   â”‚       â”œâ”€â”€ Drop irrelevant columns (Date, Machine_ID, Downtime)
â”‚   â”‚   â”‚       â”œâ”€â”€ Convert categorical â†’ numeric
â”‚   â”‚   â”‚       â”œâ”€â”€ Compute drift share using DataDriftPreset()
â”‚   â”‚   â”‚       â””â”€â”€ Categorize drift level:
â”‚   â”‚   â”‚             ğŸŸ¢ Low (<10%) â†’ Stable
â”‚   â”‚   â”‚             ğŸŸ¡ Moderate (<30%) â†’ Monitor
â”‚   â”‚   â”‚             ğŸ”´ High (â‰¥30%) â†’ Retrain
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ Automatic retraining command:
â”‚   â”‚   â”‚       os.system("dvc repro train")
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ Logging:
â”‚   â”‚           â”œâ”€â”€ logs.txt
â”‚   â”‚           â””â”€â”€ drift_history.json
â”‚   â”‚
â”‚   â”œâ”€â”€ 5ï¸âƒ£ Model Deployment
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ File:
â”‚   â”‚   â”‚       app.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ Framework: Streamlit / Flask
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ Features:
â”‚   â”‚           â”œâ”€â”€ User-friendly parameter input form
â”‚   â”‚           â”œâ”€â”€ Real-time downtime prediction
â”‚   â”‚           â””â”€â”€ SHAP visualizations for feature importance
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ”„ DVC Pipeline Definition
â”‚           â”œâ”€â”€ preprocess â†’ python src/preprocess.py
â”‚           â”œâ”€â”€ detect_drift â†’ python src/detect_drift.py
â”‚           â”œâ”€â”€ train â†’ python src/train.py
â”‚           â””â”€â”€ evaluate â†’ python src/evaluate.py
â”‚
â”œâ”€â”€ âš¡ CI/CD Automation
â”‚   â”‚
â”‚   â”œâ”€â”€ Pipeline flow:
â”‚   â”‚       â”œâ”€â”€ New data arrives â†’ triggers drift detection
â”‚   â”‚       â”œâ”€â”€ High drift â†’ triggers retraining
â”‚   â”‚       â”œâ”€â”€ Evaluation â†’ updates metrics
â”‚   â”‚       â””â”€â”€ Redeploys updated model via app.py
â”‚   â”‚
â”‚   â””â”€â”€ Supported automation:
â”‚           â”œâ”€â”€ GitHub Actions
â”‚           â””â”€â”€ AWS CodePipeline
â”‚
â”œâ”€â”€ ğŸ§¾ Logs & Monitoring
â”‚   â”‚
â”‚   â”œâ”€â”€ logs.txt               â€” Timestamped drift and retraining logs
â”‚   â”œâ”€â”€ drift_history.json     â€” Historical drift summary
â”‚   â”œâ”€â”€ reports/*.html         â€” Evidently drift visualization reports
â”‚   â””â”€â”€ reports/metrics.json   â€” Latest evaluation metrics
â”‚
â”œâ”€â”€ ğŸ§° Technologies Used
â”‚   â”‚
â”‚   â”œâ”€â”€ Data Handling: Pandas, NumPy
â”‚   â”œâ”€â”€ Modeling: Scikit-learn (RandomForestClassifier), SMOTE
â”‚   â”œâ”€â”€ Monitoring: Evidently AI
â”‚   â”œâ”€â”€ Version Control: DVC
â”‚   â”œâ”€â”€ Storage: Local / MySQL
â”‚   â”œâ”€â”€ Deployment: Streamlit / Flask
â”‚   â””â”€â”€ Automation: GitHub Actions / AWS CodePipeline
â”‚
â”œâ”€â”€ ğŸ¯ Key Features
â”‚   â”‚
â”‚   â”œâ”€â”€ âœ… Fully reproducible ML pipeline using DVC
â”‚   â”œâ”€â”€ âœ… Automated drift detection with Evidently AI
â”‚   â”œâ”€â”€ âœ… Self-healing retraining loop
â”‚   â”œâ”€â”€ âœ… Centralized configuration via params.yaml
â”‚   â”œâ”€â”€ âœ… Transparent logs and drift reports
â”‚   â””â”€â”€ âœ… Real-time prediction UI with SHAP explainability
â”‚
â”œâ”€â”€ ğŸ§© Summary
â”‚   â”‚
â”‚   â”œâ”€â”€ This project delivers a production-ready MLOps pipeline that connects data,
â”‚   â”‚   model, and deployment in a continuous feedback loop.
â”‚   â”‚
â”‚   â”œâ”€â”€ It monitors incoming data, detects drift, retrains automatically, and redeploys
â”‚   â”‚   the model.
â”‚   â”‚
â”‚   â””â”€â”€ By integrating DVC and Evidently AI, it ensures reproducibility, transparency,
â”‚       and long-term adaptability for predictive maintenance.
â”‚
â””â”€â”€ ğŸ‘¨â€ğŸ’» Author
    â”‚
    â”œâ”€â”€ Pourush Kumar Gupta
    â””â”€â”€ Machine Downtime Prediction | MLOps & Data Science | 2025
